{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_subject -> ['PT001', 'PT002', 'PT003', 'PT004', 'PT005', 'PT006', 'PT008', 'PT009', 'PT010', 'PT011', 'PT012', 'PT013', 'PT014', 'PT015', 'PT016', 'PT017', 'PT018', 'PT019', 'PT020', 'PT021', 'PT022', 'PT023', 'PT024', 'PT025', 'PT026', 'PT027', 'PT028', 'PT029', 'PT030', 'PT031', 'PT032', 'PT033', 'PT034', 'PT035', 'PT036', 'PT036', 'PT037', 'PT038', 'PT039', 'PT040', 'PT041', 'PT042', 'PT043', 'PT044', 'PT045', 'PT046', 'PT047', 'PT048', 'PT049', 'PT050', 'PT051', 'PT052', 'PT053', 'PT054', 'PT055', 'PT056', 'PT057', 'PT058', 'PT059', 'PT060', 'PT061', 'PT062', 'PT063', 'PT064', 'PT065', 'PT066', 'PT067', 'PT068', 'PT069', 'PT070', 'PT071']\n",
      "all_subject -> ['PT001', 'PT002', 'PT003', 'PT004', 'PT005', 'PT006', 'PT008', 'PT009', 'PT010', 'PT011', 'PT012', 'PT013', 'PT014', 'PT015', 'PT016', 'PT017', 'PT018', 'PT019', 'PT020', 'PT021', 'PT022', 'PT023', 'PT024', 'PT025', 'PT026', 'PT027', 'PT028', 'PT029', 'PT030', 'PT031', 'PT032', 'PT033', 'PT034', 'PT035', 'PT036', 'PT036', 'PT037', 'PT038', 'PT039', 'PT040', 'PT041', 'PT042', 'PT043', 'PT044', 'PT045', 'PT046', 'PT047', 'PT048', 'PT049', 'PT050', 'PT051', 'PT052', 'PT053', 'PT054', 'PT055', 'PT056', 'PT057', 'PT058', 'PT059', 'PT060', 'PT061', 'PT062', 'PT063', 'PT064', 'PT065', 'PT066', 'PT067', 'PT068', 'PT069', 'PT070', 'PT071']\n",
      "all_subject -> 71\n",
      "[LOSS TO FOLLOW-UP]\n",
      "[LOSS TO FOLLOW-UP]\n",
      "[LOSS TO FOLLOW-UP]\n",
      "[LOSS TO FOLLOW-UP]\n",
      "[LOSS TO FOLLOW-UP]\n",
      "[LOSS TO FOLLOW-UP]\n",
      "all_subject_index -> [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "all_subject_index.shape ->  (71,)\n",
      "len(np.unique(all_subject_index)) ->  70\n",
      "Is there any replicated number in all_subject_index? True\n",
      " Element [36] shows up in the following indices: [34 35]\n",
      " now will return replicated_indices[0::2]\n",
      "return replicated_indices [34]\n",
      "HAMD_ALL_HISTORY.shape (64, 8)\n",
      "PSYCHIATRY_HISTORY.shape (64, 15)\n",
      "CLINICAL_HISTORY.shape (64, 64)\n",
      "demographic (64, 7)\n",
      "mdd_subject_base -> (64, 1251, 52, 2)\n",
      "label_hamd -> (64, 2)\n",
      "demografic_data -> (64, 11)\n",
      "baseline_clinical_data -> (64, 7)\n",
      "dose_information -> (64, 7)\n",
      "all_involve_subject ['PT002' 'PT003' 'PT004' 'PT005' 'PT006' 'PT008' 'PT009' 'PT010' 'PT011'\n",
      " 'PT012' 'PT013' 'PT014' 'PT015' 'PT016' 'PT017' 'PT018' 'PT019' 'PT020'\n",
      " 'PT021' 'PT022' 'PT023' 'PT024' 'PT025' 'PT026' 'PT027' 'PT028' 'PT029'\n",
      " 'PT030' 'PT031' 'PT032' 'PT033' 'PT034' 'PT036' 'PT036' 'PT038' 'PT039'\n",
      " 'PT040' 'PT041' 'PT042' 'PT043' 'PT044' 'PT045' 'PT046' 'PT047' 'PT048'\n",
      " 'PT049' 'PT050' 'PT051' 'PT054' 'PT057' 'PT058' 'PT059' 'PT060' 'PT061'\n",
      " 'PT062' 'PT063' 'PT064' 'PT065' 'PT066' 'PT067' 'PT068' 'PT069' 'PT070'\n",
      " 'PT071']\n"
     ]
    }
   ],
   "source": [
    "# load \n",
    "\n",
    "import sys\n",
    "import glob\n",
    "sys.path.append('/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction')\n",
    "\n",
    "import time\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from utils.utils_mine import*\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pingouin as pg\n",
    "import subprocess\n",
    "import collections\n",
    "from utils.fnirs_utils import read_demographic, read_clinical_history, read_psychiatry_history, read_HAMD_ALL_HISTORY\n",
    "\n",
    "# path of data \n",
    "\n",
    "\n",
    "def read_from_file(example_path): # Open the file and read through the first few lines to find where the data starts\n",
    "    with open(example_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        data_start_line = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if 'Data' in line:  # This should match the unique identifier of the data section\n",
    "                data_start_line = i + 1\n",
    "                # print(lines[data_start_line])\n",
    "                break\n",
    "\n",
    "    if data_start_line is not None:\n",
    "\n",
    "        # Read the data section, skipping the lines of the metadata\n",
    "        data = pd.read_csv(example_path, skiprows=data_start_line)\n",
    "\n",
    "        # Now you have metadata and data as separate DataFrames\n",
    "        # print(data)\n",
    "    else:\n",
    "        print(\"Data section not found.\")\n",
    "        \n",
    "    np_data = data.to_numpy()\n",
    "    ch_data = np_data[:, 1:1+52]\n",
    "\n",
    "    return ch_data\n",
    "\n",
    "def get_file_name(path, rest):\n",
    "    file_pattern = os.path.join(path, rest)\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    return file_list\n",
    "\n",
    "def check_replicate_subject(all_subject):\n",
    "    all_subject_index = [i[3:] for i in all_subject]\n",
    "    all_subject_index = np.array(all_subject_index).astype(int)\n",
    "    print(f'all_subject_index -> {all_subject_index}')\n",
    "    print('all_subject_index.shape -> ', all_subject_index.shape)\n",
    "    print('len(np.unique(all_subject_index)) -> ', len(np.unique(all_subject_index)))\n",
    "    is_replicated = len(np.unique(all_subject_index)) != len(all_subject_index)\n",
    "    print(f\"Is there any replicated number in all_subject_index? {is_replicated}\")\n",
    "    if is_replicated:\n",
    "        replicated_elements = [item for item, count in collections.Counter(all_subject_index).items() if count > 1]\n",
    "        replicated_indices = np.where(np.isin(all_subject_index, replicated_elements))[0]\n",
    "        print(f\" Element {replicated_elements} shows up in the following indices: {replicated_indices}\")\n",
    "    print(f' now will return replicated_indices[0::2]')\n",
    "    return replicated_indices[0::2]\n",
    "\n",
    "\n",
    "follow_up_fold = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction/allData/RawData'\n",
    "T8_path = follow_up_fold + '/T8_fnirs/Session 2_VFT'\n",
    "base_patient_path = follow_up_fold + '/Baseline_fnirs/Patients'\n",
    "cli_path = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction/allData/fNIRS x MDD Data_Demographics_Clinical.xlsx'\n",
    "\n",
    "cgi_sgs_data = pd.read_excel(cli_path, sheet_name='SDS_CGI_All Timepoints')\n",
    "\n",
    "\n",
    "excel_data = pd.read_excel(cli_path, sheet_name='Summary T0T8_fNIRS Analysis')\n",
    "label_hamd = []\n",
    "\n",
    "\n",
    "demografic_data = []\n",
    "baseline_clinical_data = []\n",
    "\n",
    "for hb in ['_Oxy.csv', '_Deoxy.csv']:\n",
    "    tmp = 0\n",
    "    all_subject = []\n",
    "    for i in os.listdir(base_patient_path):\n",
    "        if i[-len(hb):] == hb:\n",
    "            subject = i.split(' ')[0]\n",
    "            all_subject.append(subject)\n",
    "            file_pattern = os.path.join(base_patient_path, subject+'*'+hb)\n",
    "            file_list = glob.glob(file_pattern)\n",
    "            if len(file_list) < 1:\n",
    "                print(file_list)\n",
    "            tmp+=1\n",
    "    all_subject.sort()\n",
    "    print(f'all_subject -> {all_subject}')\n",
    "print(f'all_subject -> {len(all_subject)}')\n",
    "\n",
    "medi_dose_path = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/cyrus_follow-up/data-information/medicine_info.xlsx'\n",
    "medi_dose_data = pd.read_excel(medi_dose_path, sheet_name='Sheet1')\n",
    "dose_information = []\n",
    "count_not_in_medi_dose = 0\n",
    "\n",
    "empty_subject_dose = [np.nan]*7\n",
    "\n",
    "\n",
    "\n",
    "mdd_subject_base = []#np.zeros((len(all_subject), 1251, 52, 2)) # time, channel, hbo/hbr\n",
    "all_involve_subject = []\n",
    "for sub_index, subject in enumerate(all_subject):\n",
    "    \n",
    "    hamd_of_id_t1 = excel_data[excel_data['Subject ID'] == subject]['HAM-D Questionnaire (T1)'].iloc[0]\n",
    "    hamd_of_id_t8 = excel_data[excel_data['Subject ID'] == subject]['HAM-D Questionnaire (T8)'].iloc[0]\n",
    "    if type(hamd_of_id_t8) is not int:\n",
    "        print(hamd_of_id_t8)\n",
    "        continue\n",
    "    sub_label = [hamd_of_id_t1, hamd_of_id_t8]\n",
    "    label_hamd.append(sub_label)\n",
    "    \n",
    "    demographic = excel_data[excel_data['Subject ID'] == subject].iloc[:, 2:13]\n",
    "    demografic_data.append(demographic)\n",
    "    \n",
    "    clinical = cgi_sgs_data[cgi_sgs_data['Subject ID'] == subject].iloc[:, 1:7]\n",
    "    baseline_clinical_data.append(clinical)\n",
    "    \n",
    "    medi_dose_subjects = medi_dose_data['Subject ID'].values\n",
    "    if subject not in medi_dose_subjects:\n",
    "        dose_information.append(empty_subject_dose)\n",
    "    else:\n",
    "        sub_dose_info = medi_dose_data[medi_dose_data['Subject ID'] == subject].iloc[:,3:10].values.tolist()[0]\n",
    "        dose_information.append(sub_dose_info)\n",
    "\n",
    "    \n",
    "    all_involve_subject.append(subject)\n",
    "    hbo_hbr = np.zeros((1251, 52, 2))\n",
    "    for hb_index, hb in enumerate(['_Oxy.csv', '_Deoxy.csv']):\n",
    "\n",
    "        base_hb_file = get_file_name(base_patient_path, subject+'*'+hb)\n",
    "        base_hb = read_from_file(base_hb_file[0])\n",
    "        hbo_hbr[...,hb_index] = base_hb\n",
    "    mdd_subject_base.append(hbo_hbr)\n",
    "    \n",
    "mdd_subject_base = np.array(mdd_subject_base)\n",
    "label_hamd = np.array(label_hamd)\n",
    "demografic_data = np.squeeze(np.array(demografic_data))\n",
    "baseline_clinical_data = np.squeeze(np.array(baseline_clinical_data))\n",
    "dose_information = np.array(dose_information)\n",
    "\n",
    "\n",
    "# check if there is any replicated subject, becasue there might be two files with same subject names\n",
    "replicated_indices = check_replicate_subject(all_subject)\n",
    "print(f'return replicated_indices {replicated_indices}')\n",
    "all_involve_subject = np.array(all_involve_subject)\n",
    "all_involve_subject = np.delete(all_involve_subject, replicated_indices, axis=0)\n",
    "\n",
    "HAMD_ALL_HISTORY = read_HAMD_ALL_HISTORY(cli_path, all_involve_subject)\n",
    "PSYCHIATRY_HISTORY = read_psychiatry_history(cli_path, all_involve_subject)\n",
    "CLINICAL_HISTORY = read_clinical_history(cli_path, all_involve_subject)\n",
    "demographic = read_demographic(cli_path, all_involve_subject)\n",
    "\n",
    "\n",
    "print('HAMD_ALL_HISTORY.shape', HAMD_ALL_HISTORY.shape)\n",
    "print('PSYCHIATRY_HISTORY.shape', PSYCHIATRY_HISTORY.shape)\n",
    "print('CLINICAL_HISTORY.shape', CLINICAL_HISTORY.shape)\n",
    "print('demographic', demographic.shape)\n",
    "\n",
    "\n",
    "\n",
    "# delete the replicated subject\n",
    "mdd_subject_base = np.delete(mdd_subject_base, replicated_indices, axis=0)\n",
    "label_hamd = np.delete(label_hamd, replicated_indices, axis=0)\n",
    "demografic_data = np.delete(demografic_data, replicated_indices, axis=0)\n",
    "baseline_clinical_data = np.delete(baseline_clinical_data, replicated_indices, axis=0)\n",
    "dose_information = np.delete(dose_information, replicated_indices, axis=0)\n",
    "\n",
    "# baseline HAMD will be added into the baseline_clinical_data \n",
    "baseline_clinical_data = np.concatenate((baseline_clinical_data, label_hamd[:, 0:1]), axis=1)\n",
    "\n",
    "\n",
    "print(f'mdd_subject_base -> {mdd_subject_base.shape}')\n",
    "print(f'label_hamd -> {label_hamd.shape}')\n",
    "print(f'demografic_data -> {demografic_data.shape}')\n",
    "print(f'baseline_clinical_data -> {baseline_clinical_data.shape}')\n",
    "print(f'dose_information -> {dose_information.shape}')\n",
    "print('all_involve_subject', all_involve_subject)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate remission \n",
    "label_response = np.zeros(label_hamd.shape[0])\n",
    "for i, val in enumerate(label_hamd):\n",
    "    if (val[1] - val[0]) / val[0] <= -0.5:\n",
    "        label_response[i] = 1\n",
    "        # print('label_responder[i] -> ', label_responder[i])\n",
    "        # print('val -> ',val)\n",
    "print(label_response)\n",
    "count = np.count_nonzero(label_response == 1)\n",
    "print(f\" number of remission subject in pretreatment -> {count}\")\n",
    "\n",
    "\n",
    "# modify the hb data to be like (subject, 52, 2500)\n",
    "mdd_subject_base = mdd_subject_base[:, :1250, :, :]\n",
    "mdd_subject_base = mdd_subject_base.transpose((0, 2, 1, 3))\n",
    "mdd_subject_base = mdd_subject_base.reshape((mdd_subject_base.shape[0], 52, -1))\n",
    "\n",
    "hb_data = mdd_subject_base\n",
    "\n",
    "# genrate adj matrix for gnn_transformer\n",
    "number_of_subjects = hb_data.shape[0]\n",
    "adj = generate_fnirs_adj().toarray()\n",
    "adj = np.tile(adj, (number_of_subjects, 1, 1))\n",
    "print(\"adj_matrix shape: \", adj.shape)\n",
    "\n",
    "\n",
    "output_path = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction/allData/prognosis_mix_hb/pretreatment_response'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "np.save(output_path + '/hb_data.npy', hb_data)\n",
    "np.save(output_path + '/label_hamd.npy', label_hamd)\n",
    "np.save(output_path + '/label_response.npy', label_response)\n",
    "np.save(output_path + '/label.npy', label_response)\n",
    "np.save(output_path + '/demografic_data.npy', demografic_data) # demografic is 2-13 (2-9 is demographic, 10-13 is clinical)\n",
    "np.save(output_path + '/baseline_clinical_data.npy', baseline_clinical_data)\n",
    "np.save(output_path + '/adj_matrix.npy', adj)\n",
    "\n",
    "np.save(output_path + '/HAMD_ALL_HISTORY.npy', HAMD_ALL_HISTORY)\n",
    "np.save(output_path + '/PSYCHIATRY_HISTORY.npy', PSYCHIATRY_HISTORY)\n",
    "np.save(output_path + '/CLINICAL_HISTORY.npy', CLINICAL_HISTORY)\n",
    "np.save(output_path + '/demographic.npy', demographic)\n",
    "np.save(output_path + '/dose_information.npy', dose_information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_clinical_data = np.squeeze(np.array(baseline_clinical_data))\n",
    "\n",
    "dose_information = np.array(dose_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " number of remission subject in pretreatment -> 14\n",
      "adj_matrix shape:  (64, 52, 52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanxiafeng/miniconda3/lib/python3.9/site-packages/scipy/sparse/_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
