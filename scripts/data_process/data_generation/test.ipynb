{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_subject -> 46\n",
      "all_subject_index -> [ 2  3  5  6  8  9 10 11 12 13 14 15 16 17 18 19 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45 46 48 49 50 51 54]\n",
      "all_subject_index.shape ->  (46,)\n",
      "len(np.unique(all_subject_index)) ->  46\n",
      "Is there any replicated number in all_subject_index? False\n",
      "return replicated_indices None\n",
      "mdd_subject_base -> (46, 1251, 52, 2, 2)\n",
      "label_hamd -> (46, 2)\n",
      "demografic_data -> (46, 11)\n",
      "baseline_clinical_data -> (46, 6)\n",
      "all_involve_subject ['PT002', 'PT003', 'PT005', 'PT006', 'PT008', 'PT009', 'PT010', 'PT011', 'PT012', 'PT013', 'PT014', 'PT015', 'PT016', 'PT017', 'PT018', 'PT019', 'PT021', 'PT022', 'PT023', 'PT024', 'PT025', 'PT026', 'PT027', 'PT028', 'PT029', 'PT030', 'PT031', 'PT032', 'PT033', 'PT034', 'PT036', 'PT037', 'PT038', 'PT039', 'PT040', 'PT041', 'PT042', 'PT043', 'PT044', 'PT045', 'PT046', 'PT048', 'PT049', 'PT050', 'PT051', 'PT054']\n",
      "mdd_subject_base -> (46, 1251, 52, 2, 2)\n",
      "label_hamd -> (46, 2)\n",
      "demografic_data -> (46, 11)\n",
      "baseline_clinical_data -> (46, 7)\n",
      "all_involve_subject ['PT002', 'PT003', 'PT005', 'PT006', 'PT008', 'PT009', 'PT010', 'PT011', 'PT012', 'PT013', 'PT014', 'PT015', 'PT016', 'PT017', 'PT018', 'PT019', 'PT021', 'PT022', 'PT023', 'PT024', 'PT025', 'PT026', 'PT027', 'PT028', 'PT029', 'PT030', 'PT031', 'PT032', 'PT033', 'PT034', 'PT036', 'PT037', 'PT038', 'PT039', 'PT040', 'PT041', 'PT042', 'PT043', 'PT044', 'PT045', 'PT046', 'PT048', 'PT049', 'PT050', 'PT051', 'PT054']\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " number of remission subject in posttreatment -> 5\n",
      "hb_data ->  (46, 52, 2500, 2)\n"
     ]
    }
   ],
   "source": [
    "# load \n",
    "\n",
    "import sys\n",
    "import glob\n",
    "sys.path.append('/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction')\n",
    "\n",
    "import time\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from utils.utils_mine import*\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pingouin as pg\n",
    "import subprocess\n",
    "import collections\n",
    "\n",
    "# path of data \n",
    "\n",
    "\n",
    "def read_from_file(example_path): # Open the file and read through the first few lines to find where the data starts\n",
    "    with open(example_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        data_start_line = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if 'Data' in line:  # This should match the unique identifier of the data section\n",
    "                data_start_line = i + 1\n",
    "                # print(lines[data_start_line])\n",
    "                break\n",
    "\n",
    "    if data_start_line is not None:\n",
    "\n",
    "        # Read the data section, skipping the lines of the metadata\n",
    "        data = pd.read_csv(example_path, skiprows=data_start_line)\n",
    "\n",
    "        # Now you have metadata and data as separate DataFrames\n",
    "        # print(data)\n",
    "    else:\n",
    "        print(\"Data section not found.\")\n",
    "        \n",
    "    np_data = data.to_numpy()\n",
    "    ch_data = np_data[:, 1:1+52]\n",
    "\n",
    "    return ch_data\n",
    "\n",
    "def get_file_name(path, rest):\n",
    "    file_pattern = os.path.join(path, rest)\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    return file_list\n",
    "\n",
    "def check_replicate_subject(all_subject):\n",
    "    all_subject_index = [i[3:] for i in all_subject]\n",
    "    all_subject_index = np.array(all_subject_index).astype(int)\n",
    "    print(f'all_subject_index -> {all_subject_index}')\n",
    "    print('all_subject_index.shape -> ', all_subject_index.shape)\n",
    "    print('len(np.unique(all_subject_index)) -> ', len(np.unique(all_subject_index)))\n",
    "    is_replicated = len(np.unique(all_subject_index)) != len(all_subject_index)\n",
    "    print(f\"Is there any replicated number in all_subject_index? {is_replicated}\")\n",
    "    if is_replicated:\n",
    "        replicated_elements = [item for item, count in collections.Counter(all_subject_index).items() if count > 1]\n",
    "        replicated_indices = np.where(np.isin(all_subject_index, replicated_elements))[0]\n",
    "        print(f\" Element {replicated_elements} shows up in the following indices: {replicated_indices}\")\n",
    "    else: return None\n",
    "    print(f' now will return replicated_indices[0::2]')\n",
    "    return replicated_indices[0::2]\n",
    "\n",
    "\n",
    "follow_up_fold = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction/allData/RawData'\n",
    "T8_path = follow_up_fold + '/T8_fnirs/Session 2_VFT'\n",
    "base_patient_path = follow_up_fold + '/Baseline_fnirs/Patients'\n",
    "cli_path = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction/allData/fNIRS x MDD Data_Demographics_Clinical.xlsx'\n",
    "\n",
    "cgi_sgs_data = pd.read_excel(cli_path, sheet_name='SDS_CGI_All Timepoints')\n",
    "\n",
    "# cgi_sgs_data.iloc[:, 1:7]\n",
    "\n",
    "excel_data = pd.read_excel(cli_path, sheet_name='Summary T0T8_fNIRS Analysis')\n",
    "# cgi_sgs_data = pd.read_excel(cgi_sgs_path, sheet_name='SDS_CGI_All Timepoints')\n",
    "label_hamd = []\n",
    "demografic_data = []\n",
    "baseline_clinical_data = []\n",
    "\n",
    "def check_existing_subject_in_fnirs_path(path):\n",
    "    for hb in ['_Oxy.csv', '_Deoxy.csv']:\n",
    "        tmp = 0\n",
    "        all_subject = []\n",
    "        for i in os.listdir(path):\n",
    "            if i[-len(hb):] == hb:\n",
    "                subject = i.split(' ')[0]\n",
    "                all_subject.append(subject)\n",
    "                file_pattern = os.path.join(path, subject+'*'+hb)\n",
    "                file_list = glob.glob(file_pattern)\n",
    "                if len(file_list) < 1:\n",
    "                    print(file_list)\n",
    "                tmp+=1\n",
    "        all_subject.sort()\n",
    "    return all_subject\n",
    "\n",
    "all_subject = check_existing_subject_in_fnirs_path(T8_path)\n",
    "print(f'all_subject -> {len(all_subject)}')\n",
    "\n",
    "# def get_file_name(path, rest):\n",
    "#     file_pattern = os.path.join(path, rest)\n",
    "#     file_list = glob.glob(file_pattern)\n",
    "#     return file_list\n",
    "# # according to the subject name of all_subject create array now \n",
    "\n",
    "mdd_subject_base_post = np.zeros((len(all_subject), 1251, 52, 2, 2))# []#np.zeros((len(all_subject), 1251, 52, 2)) # time, channel, hbo/hbr\n",
    "all_involve_subject = []\n",
    "for sub_index, subject in enumerate(all_subject):\n",
    "    hamd_of_id_t1 = excel_data[excel_data['Subject ID'] == subject]['HAM-D Questionnaire (T1)'].iloc[0]\n",
    "    hamd_of_id_t8 = excel_data[excel_data['Subject ID'] == subject]['HAM-D Questionnaire (T8)'].iloc[0]\n",
    "    demographic = excel_data[excel_data['Subject ID'] == subject].iloc[:, 2:13]\n",
    "    clinical = cgi_sgs_data[cgi_sgs_data['Subject ID'] == subject].iloc[:, 1:7]\n",
    "    if type(hamd_of_id_t8) is not int:\n",
    "        print(hamd_of_id_t8)\n",
    "        continue\n",
    "    all_involve_subject.append(subject)\n",
    "    sub_label = [hamd_of_id_t1, hamd_of_id_t8]\n",
    "    label_hamd.append(sub_label)\n",
    "    demografic_data.append(demographic)\n",
    "    baseline_clinical_data.append(clinical)\n",
    "    for hb_index, hb in enumerate(['_Oxy.csv', '_Deoxy.csv']):\n",
    "\n",
    "        base_hb_file = get_file_name(base_patient_path, subject+'*'+hb)\n",
    "        base_hb = read_from_file(base_hb_file[0])\n",
    "        \n",
    "        post_hb_file = get_file_name(T8_path, subject+'*'+hb)\n",
    "        post_hb = read_from_file(post_hb_file[0])\n",
    "        \n",
    "        mdd_subject_base_post[sub_index, :, :, hb_index, 0] = base_hb\n",
    "        mdd_subject_base_post[sub_index, :, :, hb_index, 1] = post_hb\n",
    "        # print(f\"sub :{sub_index} ({subject}) hb: {hb_index} was given base value {np.mean(base_hb)} and post value {np.mean(post_hb)}\")\n",
    "\n",
    "mdd_subject_base = np.array(mdd_subject_base_post)\n",
    "label_hamd = np.array(label_hamd)\n",
    "demografic_data = np.squeeze(np.array(demografic_data))\n",
    "baseline_clinical_data = np.squeeze(np.array(baseline_clinical_data))\n",
    "\n",
    "\n",
    "# check if there is any replicated subject, becasue there might be two files with same subject names\n",
    "replicated_indices = check_replicate_subject(all_subject)\n",
    "print(f'return replicated_indices {replicated_indices}')\n",
    "\n",
    "print(f'mdd_subject_base -> {mdd_subject_base.shape}')\n",
    "print(f'label_hamd -> {label_hamd.shape}')\n",
    "print(f'demografic_data -> {demografic_data.shape}')\n",
    "print(f'baseline_clinical_data -> {baseline_clinical_data.shape}')\n",
    "print('all_involve_subject', all_involve_subject)\n",
    "\n",
    "# delete the replicated subject\n",
    "if replicated_indices:\n",
    "    mdd_subject_base = np.delete(mdd_subject_base, replicated_indices, axis=0)\n",
    "    label_hamd = np.delete(label_hamd, replicated_indices, axis=0)\n",
    "    demografic_data = np.delete(demografic_data, replicated_indices, axis=0)\n",
    "    baseline_clinical_data = np.delete(baseline_clinical_data, replicated_indices, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# baseline HAMD will be added into the baseline_clinical_data \n",
    "baseline_clinical_data = np.concatenate((baseline_clinical_data, label_hamd[:, 0:1]), axis=1)\n",
    "\n",
    "\n",
    "print(f'mdd_subject_base -> {mdd_subject_base.shape}')\n",
    "print(f'label_hamd -> {label_hamd.shape}')\n",
    "print(f'demografic_data -> {demografic_data.shape}')\n",
    "print(f'baseline_clinical_data -> {baseline_clinical_data.shape}')\n",
    "print('all_involve_subject', all_involve_subject)\n",
    "\n",
    "# calculate remission \n",
    "label_remission = np.zeros(label_hamd.shape[0])\n",
    "for i, val in enumerate(label_hamd):\n",
    "    if val[0] >= 7 and val[1] <= 7:\n",
    "        if val[0] == 7: print(f\" val[0] == 7 : i -> {i} | val[1] -> {val[1]}\")\n",
    "        if val[1] == 7: print(f\" val[1] == 7 : i -> {i} | val[0] -> {val[0]}\")\n",
    "        label_remission[i] = 1\n",
    "        # print('label_responder[i] -> ', label_responder[i])\n",
    "        # print('val -> ',val)\n",
    "print(label_remission)\n",
    "count = np.count_nonzero(label_remission == 1)\n",
    "print(f\" number of remission subject in posttreatment -> {count}\")\n",
    "\n",
    "\n",
    "# modify the hb data (46, 1251, 52, 2, 2) to be like (subject, 52, 2500, 2)\n",
    "mdd_subject_base = mdd_subject_base[:, :1250, :, :, :]\n",
    "mdd_subject_base = mdd_subject_base.transpose((0, 2, 1, 3, 4))\n",
    "mdd_subject_base = mdd_subject_base.reshape((mdd_subject_base.shape[0], 52, 2500, 2))\n",
    "\n",
    "hb_data = mdd_subject_base\n",
    "print('hb_data -> ', hb_data.shape)\n",
    "\n",
    "output_path = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction/allData/prognosis/posttreatment_remission'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "np.save(output_path + '/hb_data.npy', hb_data)\n",
    "np.save(output_path + '/label_hamd.npy', label_hamd)\n",
    "np.save(output_path + '/label.npy', label_remission)\n",
    "np.save(output_path + '/label_remission.npy', label_remission)\n",
    "np.save(output_path + '/demografic_data.npy', demografic_data)\n",
    "np.save(output_path + '/baseline_clinical_data.npy', baseline_clinical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdd_subject_base -> (46, 52, 2500, 2)\n",
      "label_hamd -> (46, 2)\n",
      "demografic_data -> (46, 11)\n",
      "baseline_clinical_data -> (46, 9)\n",
      "all_involve_subject ['PT002', 'PT003', 'PT005', 'PT006', 'PT008', 'PT009', 'PT010', 'PT011', 'PT012', 'PT013', 'PT014', 'PT015', 'PT016', 'PT017', 'PT018', 'PT019', 'PT021', 'PT022', 'PT023', 'PT024', 'PT025', 'PT026', 'PT027', 'PT028', 'PT029', 'PT030', 'PT031', 'PT032', 'PT033', 'PT034', 'PT036', 'PT037', 'PT038', 'PT039', 'PT040', 'PT041', 'PT042', 'PT043', 'PT044', 'PT045', 'PT046', 'PT048', 'PT049', 'PT050', 'PT051', 'PT054']\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 4-dimensional, but 5 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(count)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# modify the hb data (46, 1251, 52, 2, 2) to be like (subject, 52, 2500, 2)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m mdd_subject_base \u001b[38;5;241m=\u001b[39m \u001b[43mmdd_subject_base\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m mdd_subject_base \u001b[38;5;241m=\u001b[39m mdd_subject_base\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     28\u001b[0m mdd_subject_base \u001b[38;5;241m=\u001b[39m mdd_subject_base\u001b[38;5;241m.\u001b[39mreshape((mdd_subject_base\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m52\u001b[39m, \u001b[38;5;241m2500\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 4-dimensional, but 5 were indexed"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hb_data ->  (64, 52, 2500)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgi_sgs_path = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction/allData/fNIRS x MDD Data_Demographics_Clinical.xlsx'\n",
    "\n",
    "cgi_sgs_data = pd.read_excel(cgi_sgs_path, sheet_name='SDS_CGI_All Timepoints')\n",
    "\n",
    "cgi_sgs_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
