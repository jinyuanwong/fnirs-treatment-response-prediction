{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current system is Ubuntu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 20:24:27.768974: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-30 20:24:27.788098: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:7704] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-30 20:24:27.788117: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-30 20:24:27.788126: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1520] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-30 20:24:27.792656: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-30 20:24:28.092193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model Name | Testing Set |             |             |             | Validation Set |             |             |             |\n",
      "|------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|\n",
      "|            | Balanced Accuracy | Sensitivity | Specificity | AUC | Balanced Accuracy | Sensitivity | Specificity | AUC |\n",
      "| eval_1m   | 66.0000  | 72.0000  | 60.0000  | 69.2770  | 58.1892  | 64.8890  | 51.4894  | 58.9550  |\n",
      "| eval_2m   | 57.0770  | 48.0000  | 66.1540  | 61.8460  | 57.6737  | 50.6668  | 64.6806  | 55.8346  |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jy/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/jy/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.14.0-dev20230531). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "def set_path():\n",
    "    if sys.platform == 'darwin':\n",
    "        print(\"Current system is macOS\")\n",
    "        main_fold_path = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction'\n",
    "    elif sys.platform == 'linux':\n",
    "        print(\"Current system is Ubuntu\")\n",
    "        main_fold_path = '/home/jy/Documents/fnirs/treatment_response/fnirs-depression-deeplearning'\n",
    "    else:\n",
    "        print(\"Current system is neither macOS nor Ubuntu\")\n",
    "    os.chdir(main_fold_path)\n",
    "    \n",
    "set_path()    \n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "def get_best_acc_epoch(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    index_of_best_acc = df['val_accuracy'].argmax()\n",
    "    return index_of_best_acc\n",
    "\n",
    "import glob \n",
    "\n",
    "def delete_files_starting_with(directory, prefix):\n",
    "    pattern = os.path.join(directory, '*' + prefix + '*') \n",
    "    files_to_delete = glob.glob(pattern)\n",
    "    for file in files_to_delete:\n",
    "        try: \n",
    "            os.remove(file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "\n",
    "model_name = 'cnn_transformer'\n",
    "config_name = 'skf_v0mdd_classification_jamba'\n",
    "dataset = 'diagnosis514'\n",
    "model_config_dict = {\n",
    "    # 'jamba_multimodal':[ f'eval{i}mdd_classification_jamba' for i in range(2)],\n",
    "    # 'cnn_transformer': [f'eval{i}mdd_classification_jamba_subject_110_hb_simple_all_1d_SPECIFY_FOLD_5_nor' for i in range(1, 6)],\n",
    "    'mamba': [f'eval_{i}mdd_classification_mamba_subject_all_seq_ch_hb_data_1d_SPECIFY_FOLD_5_nor_with_glbpool' for i in range(1, 3)],\n",
    "    # 'jamba': [f're{i}mdd_classification_jamba_subject_110_hb_simple_all_1d_SPECIFY_FOLD_5_nor' for i in range(1, 6)] \\\n",
    "    #     + [f'eval{i}mdd_classification_jamba_subject_110_hb_simple_all_1d_SPECIFY_FOLD_5_nor' for i in range(1, 6)] \\\n",
    "    #     + [f'eval{i}mdd_classification_jamba_subject_110_hb_simple_all_1d_SPECIFY_FOLD_5_nor_chkpt' for i in range(1, 6)] \\\n",
    "    #     + ['re_eval3_1mdd_classification_jamba_subject_110_hb_simple_all_1d_SPECIFY_FOLD_5_nor'] \\\n",
    "    #     + ['t11mdd_classification_jamba_subject_250_hb_simple_all_1d_SPECIFY_FOLD_AND_HOLD_5_nor'],\n",
    "    #      + [f'eval{i}mdd_classification_jamba_subject_110_hb_simple_all_1d_SPECIFY_FOLD_5_nor' for i in range(1, 6)],\n",
    "    # 'jamba': ['eval1mdd_classification_jamba_subject_483',\n",
    "    #           'eval2mdd_classification_jamba_subject_483'],\n",
    "    # 'jamba': np.flip(['skf_v0mdd_classification_jamba', \n",
    "    #           'skf_v1_2layersmdd_classification_jamba', \n",
    "    #           'skf_v1_1layers_64_modelstatesmdd_classification_jamba',\n",
    "    #           'skf_v2_sin_lrmdd_classification_jamba',\n",
    "    #           'skf_v4_1e5_lrbeginmdd_classification_jamba',\n",
    "    #           'skf_v5_no_mean_premdd_classification_jamba',\n",
    "    #           'skf_v6_3layers_256_input_dimsmdd_classification_jamba',\n",
    "    #           'skf_v7_3layers_256dims_9blocksmdd_classification_jamba',\n",
    "    #           'skf_v8_2layersmdd_classification_jamba',\n",
    "    #           'skf_v9_4layersmdd_classification_jamba',\n",
    "    #           'skf_s0mdd_classification_jamba',\n",
    "    #           'skf_s1_conv1d_longmdd_classification_jamba',\n",
    "    #           'skf_s2_conv1d_1000epochs_1e9lrmdd_classification_jamba',\n",
    "    #           'skf_s3_1000epochs_1e6lrmdd_classification_jamba',\n",
    "    #           'skf_s4_1e-5lrmdd_classification_jamba',\n",
    "    #           'skf_s5mdd_classification_jamba',\n",
    "    #           'skf_s6_replicationmdd_classification_jamba',\n",
    "    #           'skf_s7_replicat_5000warmupmdd_classification_jamba',\n",
    "    #           'skf_s8_valaccmdd_classification_jamba',\n",
    "    #           'skf_s9_valloss_50patiencesmdd_classification_jamba',\n",
    "    #           'skf_s10_300patiencesmdd_classification_jamba']),\n",
    "    # 'mamba': ['skf_v0mdd_classification_mamba']\n",
    "}\n",
    "num_of_k_fold = 5\n",
    "\n",
    "validation_name = f'SKF_holdout/stratified_nested_{num_of_k_fold}_CV_fold'\n",
    "\n",
    "# reading the last index of result\n",
    "# def find_path_acc(path):\n",
    "#     with open(path, 'r') as f:\n",
    "#         acc = f.read()\n",
    "#     acc = acc.split('\\n')[-2]\n",
    "#     acc = re.findall(r'accuracy: (\\d+\\.\\d+)', acc)[0]\n",
    "    \n",
    "#     return np.float(acc)\n",
    "\n",
    "def find_path_metrics(path):\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    accuracy = re.findall(r'accuracy: (\\d+\\.\\d+)', content)[0]\n",
    "    sensitivity = re.findall(r'sensitivity: (\\d+\\.\\d+)', content)[0]\n",
    "    specificity = re.findall(r'specificity: (\\d+\\.\\d+)', content)[0]\n",
    "    auc = re.findall(r'AUC: (\\d+\\.\\d+)', content)[0]\n",
    "\n",
    "    # Convert the extracted strings to floats\n",
    "    accuracy = float(accuracy)\n",
    "    sensitivity = float(sensitivity)\n",
    "    specificity = float(specificity)\n",
    "    auc = float(auc)\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, auc\n",
    "from utils.fnirs_utils import print_md_table_val_test_AUC\n",
    "def read_model_config_result(model_name, config_name, validation_name='SKF_holdout/stratified_nested_10_CV_fold', num_of_k_fold=10):\n",
    "    test_metrics = []\n",
    "    val_metrics = []\n",
    "    index_best = []\n",
    "    for k in range(num_of_k_fold):\n",
    "        path = f'results/{model_name}/{dataset}/{config_name}/{validation_name}-{k}' \n",
    "        fold_test_acc = find_path_metrics(path + '/test_acc.txt')\n",
    "        fold_val_acc = find_path_metrics(path + '/val_acc.txt')\n",
    "        fold_index_best = get_best_acc_epoch(path + '/history.csv')\n",
    "        index_best.append(fold_index_best)\n",
    "        test_metrics.append(fold_test_acc)\n",
    "        val_metrics.append(fold_val_acc)\n",
    "\n",
    "        # delete checkpoint files, in case the space is not enough\n",
    "        delete_files_starting_with(path, 'checkpoint')\n",
    "    head_print = True if config_name[:7] == 'skf_s10' else False\n",
    "    print_md_table_val_test_AUC(config_name[:7], np.mean(test_metrics, axis=0), np.mean(val_metrics,axis=0), print_table_header=head_print, already_balanced_accuracy=False)\n",
    "    # print(val_metrics)\n",
    "    # print('model_name:', model_name, config_name)\n",
    "    # print('test_acc:', np.mean(test_metrics))\n",
    "    # print('val_acc:', np.mean(val_metrics))\n",
    "    # print('index_best:', np.mean(index_best))\n",
    "\n",
    "from utils.utils_mine import plot_evaluation_metrics_header\n",
    "plot_evaluation_metrics_header()\n",
    "for model_name, config_names in model_config_dict.items():\n",
    "    for config_name in config_names:\n",
    "        read_model_config_result(model_name, config_name, validation_name, num_of_k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the best acc and its corresponding epoch \n",
    "import pandas as pd \n",
    "def get_best_acc_epoch(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    index_of_best_acc = df['val_accuracy'].argmax()\n",
    "    return index_of_best_acc\n",
    "# csv_file = '/home/jy/Documents/fnirs/treatment_response/fnirs-depression-deeplearning/results/jamba/diagnosis514/skf_s2_conv1d_1000epochs_1e9lrmdd_classification_jamba/SKF_holdout/stratified_nested_10_CV_fold-9/history.csv'\n",
    "# df = pd.read_csv(csv_file)\n",
    "# index_of_best_acc = df['val_accuracy'].argmax()\n",
    "# index_of_best_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
