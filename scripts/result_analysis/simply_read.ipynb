{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current system is Ubuntu\n",
      "| eval1md   | 59.8090  | 46.8181  | 72.8000  | 59.8092  | 73.2272  | 66.0000  | 80.4545  | 73.2274  |\n",
      "| eval2md   | 62.5636  | 52.7273  | 72.4000  | 62.5637  | 75.3637  | 73.0000  | 77.7274  | 75.3637  |\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "def set_path():\n",
    "    if sys.platform == 'darwin':\n",
    "        print(\"Current system is macOS\")\n",
    "        main_fold_path = '/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction'\n",
    "    elif sys.platform == 'linux':\n",
    "        print(\"Current system is Ubuntu\")\n",
    "        main_fold_path = '/home/jy/Documents/fnirs/treatment_response/fnirs-depression-deeplearning'\n",
    "    else:\n",
    "        print(\"Current system is neither macOS nor Ubuntu\")\n",
    "    os.chdir(main_fold_path)\n",
    "    \n",
    "set_path()    \n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "def get_best_acc_epoch(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    index_of_best_acc = df['val_accuracy'].argmax()\n",
    "    return index_of_best_acc\n",
    "\n",
    "import glob \n",
    "\n",
    "def delete_files_starting_with(directory, prefix):\n",
    "    pattern = os.path.join(directory, '*' + prefix + '*') \n",
    "    files_to_delete = glob.glob(pattern)\n",
    "    for file in files_to_delete:\n",
    "        try: \n",
    "            os.remove(file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "\n",
    "model_name = 'cnn_transformer'\n",
    "config_name = 'skf_v0mdd_classification_jamba'\n",
    "dataset = 'diagnosis_406_less_than_threshold'\n",
    "model_config_dict = {\n",
    "    # 'jamba_multimodal':[ f'eval{i}mdd_classification_jamba' for i in range(2)],\n",
    "    # 'cnn_transformer': ['skf_v0mdd_classification_jamba'],\n",
    "    'jamba': ['eval1mdd_classification_jamba_subject_406',\n",
    "              'eval2mdd_classification_jamba_subject_406'],\n",
    "    # 'jamba': ['eval1mdd_classification_jamba_subject_483',\n",
    "    #           'eval2mdd_classification_jamba_subject_483'],\n",
    "    # 'jamba': np.flip(['skf_v0mdd_classification_jamba', \n",
    "    #           'skf_v1_2layersmdd_classification_jamba', \n",
    "    #           'skf_v1_1layers_64_modelstatesmdd_classification_jamba',\n",
    "    #           'skf_v2_sin_lrmdd_classification_jamba',\n",
    "    #           'skf_v4_1e5_lrbeginmdd_classification_jamba',\n",
    "    #           'skf_v5_no_mean_premdd_classification_jamba',\n",
    "    #           'skf_v6_3layers_256_input_dimsmdd_classification_jamba',\n",
    "    #           'skf_v7_3layers_256dims_9blocksmdd_classification_jamba',\n",
    "    #           'skf_v8_2layersmdd_classification_jamba',\n",
    "    #           'skf_v9_4layersmdd_classification_jamba',\n",
    "    #           'skf_s0mdd_classification_jamba',\n",
    "    #           'skf_s1_conv1d_longmdd_classification_jamba',\n",
    "    #           'skf_s2_conv1d_1000epochs_1e9lrmdd_classification_jamba',\n",
    "    #           'skf_s3_1000epochs_1e6lrmdd_classification_jamba',\n",
    "    #           'skf_s4_1e-5lrmdd_classification_jamba',\n",
    "    #           'skf_s5mdd_classification_jamba',\n",
    "    #           'skf_s6_replicationmdd_classification_jamba',\n",
    "    #           'skf_s7_replicat_5000warmupmdd_classification_jamba',\n",
    "    #           'skf_s8_valaccmdd_classification_jamba',\n",
    "    #           'skf_s9_valloss_50patiencesmdd_classification_jamba',\n",
    "    #           'skf_s10_300patiencesmdd_classification_jamba']),\n",
    "    # 'mamba': ['skf_v0mdd_classification_mamba']\n",
    "}\n",
    "validation_name = 'SKF_holdout/stratified_nested_10_CV_fold'\n",
    "num_of_k_fold = 10\n",
    "\n",
    "# reading the last index of result\n",
    "# def find_path_acc(path):\n",
    "#     with open(path, 'r') as f:\n",
    "#         acc = f.read()\n",
    "#     acc = acc.split('\\n')[-2]\n",
    "#     acc = re.findall(r'accuracy: (\\d+\\.\\d+)', acc)[0]\n",
    "    \n",
    "#     return np.float(acc)\n",
    "\n",
    "def find_path_metrics(path):\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    accuracy = re.findall(r'accuracy: (\\d+\\.\\d+)', content)[0]\n",
    "    sensitivity = re.findall(r'sensitivity: (\\d+\\.\\d+)', content)[0]\n",
    "    specificity = re.findall(r'specificity: (\\d+\\.\\d+)', content)[0]\n",
    "    auc = re.findall(r'AUC: (\\d+\\.\\d+)', content)[0]\n",
    "\n",
    "    # Convert the extracted strings to floats\n",
    "    accuracy = float(accuracy)\n",
    "    sensitivity = float(sensitivity)\n",
    "    specificity = float(specificity)\n",
    "    auc = float(auc)\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, auc\n",
    "from utils.fnirs_utils import print_md_table_val_test_AUC\n",
    "def read_model_config_result(model_name, config_name, validation_name='SKF_holdout/stratified_nested_10_CV_fold', num_of_k_fold=10):\n",
    "    test_metrics = []\n",
    "    val_metrics = []\n",
    "    index_best = []\n",
    "    for k in range(num_of_k_fold):\n",
    "        path = f'results/{model_name}/{dataset}/{config_name}/{validation_name}-{k}' \n",
    "        fold_test_acc = find_path_metrics(path + '/test_acc.txt')\n",
    "        fold_val_acc = find_path_metrics(path + '/val_acc.txt')\n",
    "        fold_index_best = get_best_acc_epoch(path + '/history.csv')\n",
    "        index_best.append(fold_index_best)\n",
    "        test_metrics.append(fold_test_acc)\n",
    "        val_metrics.append(fold_val_acc)\n",
    "\n",
    "        # delete checkpoint files, in case the space is not enough\n",
    "        delete_files_starting_with(path, 'checkpoint')\n",
    "    head_print = True if config_name[:7] == 'skf_s10' else False\n",
    "    print_md_table_val_test_AUC(config_name[:7], np.mean(test_metrics, axis=0), np.mean(val_metrics,axis=0), print_table_header=head_print, already_balanced_accuracy=False)\n",
    "    # print(val_metrics)\n",
    "    # print('model_name:', model_name, config_name)\n",
    "    # print('test_acc:', np.mean(test_metrics))\n",
    "    # print('val_acc:', np.mean(val_metrics))\n",
    "    # print('index_best:', np.mean(index_best))\n",
    "\n",
    "\n",
    "for model_name, config_names in model_config_dict.items():\n",
    "    for config_name in config_names:\n",
    "        read_model_config_result(model_name, config_name, validation_name, num_of_k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mval_metrics\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_metrics' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the best acc and its corresponding epoch \n",
    "import pandas as pd \n",
    "def get_best_acc_epoch(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    index_of_best_acc = df['val_accuracy'].argmax()\n",
    "    return index_of_best_acc\n",
    "# csv_file = '/home/jy/Documents/fnirs/treatment_response/fnirs-depression-deeplearning/results/jamba/diagnosis514/skf_s2_conv1d_1000epochs_1e9lrmdd_classification_jamba/SKF_holdout/stratified_nested_10_CV_fold-9/history.csv'\n",
    "# df = pd.read_csv(csv_file)\n",
    "# index_of_best_acc = df['val_accuracy'].argmax()\n",
    "# index_of_best_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
