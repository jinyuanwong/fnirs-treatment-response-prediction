{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanxiafeng/miniconda3/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/shanxiafeng/miniconda3/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.14.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from wandb.keras import WandbCallback\n",
    "import sys\n",
    "import time\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from utils.utils_mine import *\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow_addons as tfa\n",
    "import wandb\n",
    "import config\n",
    "import gc\n",
    "from classifiers.classifier_factory import create_classifier\n",
    "from scripts.plot.DL.read_LOO_nestedCV_gnntr import get_sorted_loo_array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''/Users/shanxiafeng/Documents/Project/Research/fnirs-prognosis/code/fnirs-treatment-response-prediction/results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_0/stratified_nested_5_CV_fold-0    '''\n",
    "\n",
    "\n",
    "def get_sorted_loo_array(model, model_params):\n",
    "    ALL_TOTAL_ITERATION = []\n",
    "    TOTAL_Subject = 65\n",
    "    K_FOLD = 5\n",
    "    validation_method_external = 'LOO_nested_CV'\n",
    "    validation_method_inner = 'stratified_nested_5_CV_fold'\n",
    "    DATASET = 'prognosis/pre_treatment_hamd_reduction_50'\n",
    "    RESULT_FILE_NAME = 'val_acc.txt'\n",
    "    val_fold_path = f'results/{model}/{DATASET}/{model_params}/{validation_method_external}'\n",
    "    total_subjects  = 46 if DATASET[:8] == 'pre_post' else TOTAL_Subject # '65' or '46\n",
    "\n",
    "\n",
    "    for subject in range(total_subjects):\n",
    "        for fold in range(K_FOLD):\n",
    "            fold_path = f'{val_fold_path}/LOO_{subject}/{validation_method_inner}-{fold}'\n",
    "            try:\n",
    "                with open(f'{fold_path}/{RESULT_FILE_NAME}', 'r') as f:\n",
    "                    best_iteration = int(f.read())\n",
    "                    ALL_TOTAL_ITERATION.append(best_iteration)\n",
    "            except:\n",
    "                print(f'Error: {fold_path}/best_iteration.txt not found')\n",
    "            \n",
    "    loo_toal_itr = np.array(ALL_TOTAL_ITERATION).copy()\n",
    "    loo_toal_itr = loo_toal_itr.reshape(-1, 5)\n",
    "    loo_toal_itr = np.mean(loo_toal_itr, axis=1)\n",
    "    sorted_indices = np.argsort(loo_toal_itr)\n",
    "    sorted_indices = sorted_indices.tolist()\n",
    "    print(\"Sorted indices:\", sorted_indices, \"Sorted values:\", loo_toal_itr[sorted_indices])\n",
    "    return sorted_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_path results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-0\n",
      "results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-0/val_acc.txt will be set to 0 because it has not been trained yet\n",
      "fold_path results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-1\n",
      "results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-1/val_acc.txt will be set to 0 because it has not been trained yet\n",
      "fold_path results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-2\n",
      "results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-2/val_acc.txt will be set to 0 because it has not been trained yet\n",
      "fold_path results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-3\n",
      "results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-3/val_acc.txt will be set to 0 because it has not been trained yet\n",
      "fold_path results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-4\n",
      "results/yu_gnn/prognosis/pre_treatment_hamd_reduction_50/v1/LOO_nested_CV/LOO_64/stratified_nested_5_CV_fold-4/val_acc.txt will be set to 0 because it has not been trained yet\n",
      "[64, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 33, 63, 32, 30, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = 'yu_gnn'\n",
    "model_params = 'v1'\n",
    "\n",
    "def avg_total_itr_for_each_fold(ALL_TOTAL_ITERATION):\n",
    "        loo_toal_itr = np.array(ALL_TOTAL_ITERATION).copy()\n",
    "        loo_toal_itr = loo_toal_itr.reshape(-1, 5)\n",
    "        loo_toal_itr = np.mean(loo_toal_itr, axis=1)\n",
    "        return loo_toal_itr\n",
    "def get_sorted_loo_array(model, model_params):\n",
    "\n",
    "    ALL_TOTAL_ITERATION = [] # store all the total iteration for each fold\n",
    "    TOTAL_Subject = 65 # number of subjects in the dataset for LOOCV in external testing set\n",
    "    K_FOLD = 5 # number of k folds in inner CV\n",
    "    validation_method_external = 'LOO_nested_CV' # external validation method\n",
    "    validation_method_inner = 'stratified_nested_5_CV_fold' # inner validation method\n",
    "    DATASET = 'prognosis/pre_treatment_hamd_reduction_50' # dataset name\n",
    "    RESULT_FILE_NAME = 'val_acc.txt' # result file name\n",
    "    val_fold_path = f'results/{model}/{DATASET}/{model_params}/{validation_method_external}'\n",
    "    total_subjects  = 46 if DATASET[:8] == 'pre_post' else TOTAL_Subject # '65' or '46\n",
    "\n",
    "\n",
    "    for subject in range(total_subjects):\n",
    "        for fold in range(K_FOLD):\n",
    "            fold_path = f'{val_fold_path}/LOO_{subject}/{validation_method_inner}-{fold}'\n",
    "            try:\n",
    "                with open(f'{fold_path}/{RESULT_FILE_NAME}', 'r') as f:\n",
    "\n",
    "                    total_lines = len(f.readlines())\n",
    "                    ALL_TOTAL_ITERATION.append(total_lines)\n",
    "            except:\n",
    "                # if the fold has not been created yet, then the total iteration is 0\n",
    "                print('fold_path', fold_path)\n",
    "                ALL_TOTAL_ITERATION.append(0)\n",
    "                print(f'{fold_path}/{RESULT_FILE_NAME} will be set to 0 because it has not been trained yet')\n",
    "    # average the total iteration for each fold\n",
    "    loo_toal_itr = avg_total_itr_for_each_fold(ALL_TOTAL_ITERATION)\n",
    "    sorted_indices = np.argsort(loo_toal_itr)\n",
    "    sorted_indices = sorted_indices.tolist()\n",
    "    \n",
    "    # print(\"Sorted indices:\", sorted_indices, \"Sorted values:\", loo_toal_itr[sorted_indices])\n",
    "    return sorted_indices\n",
    "\n",
    "sorted_indices = get_sorted_loo_array(model, model_params)\n",
    "print(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42887446, 0.57112557], [0.8382789, 0.16172114], [0.5024056, 0.4975944]]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_to_float(value):\n",
    "    value = np.array(value)\n",
    "    try:\n",
    "        final_value = value.astype(float)\n",
    "        np.nan_to_num(final_value, nan=0.0)\n",
    "    except ValueError:\n",
    "        final_value = 0.0\n",
    "    return final_value\n",
    "\n",
    "\n",
    "def read_file_metric_y_pred(path):\n",
    "    pattern = r\"Y_pred_in_test: \\[\\[(.*?)\\]\\]\"\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "        y_pred = re.findall(pattern, content)\n",
    "    numbers_list = np.array([float(num) for s in y_pred for num in s.split()]).reshape(-1, 2).tolist()\n",
    "\n",
    "    return numbers_list\n",
    "\n",
    "str_list = read_file_metric_y_pred('/home/jy/Documents/fnirs/treatment_response/fnirs-depression-deeplearning/results/gnn_transformer/prognosis/pre_treatment_hamd_reduction_50/v2_repeat_3l1_rate_0.01_l2_rate_0.01_d_model_16_batch_size_64_n_layers_6/LOO_nested_CV/LOO_0/stratified_nested_5_CV_fold-1/test_acc.txt')\n",
    "print(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42887446, 0.57112557], [0.8382789, 0.16172114], [0.5024056, 0.4975944]]\n"
     ]
    }
   ],
   "source": [
    "numbers_list = np.array([float(num) for s in str_list for num in s.split()]).reshape(-1, 2).tolist()\n",
    "print(numbers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_fold_path results/gnn_transformer/prognosis/pre_treatment_hamd_reduction_50/v2_repeat_1l1_rate_0.01_l2_rate_0.01_d_model_16_batch_size_64_n_layers_6/LOO_nested_CV/LOO_0\n",
      "num_of_cv_folds 5\n",
      "y_test [0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1]\n",
      "MAX_ITR: 999 ranging ( 3 ~ 10 )\n",
      "Model name: gnn_transformer\n",
      "| Model Name | Testing Set |             |             |             | Validation Set |             |             |             |\n",
      "|------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|-------------|\n",
      "|            | Balanced Accuracy | Sensitivity | Specificity | F1 Score | Balanced Accuracy | Sensitivity | Specificity | F1 Score |\n",
      "| gnn_transformer   | 65.0000  | 40.0000  | 90.0000  | 46.1538  | 83.2257  | 76.4617  | 89.9898  | 86.8218  |\n",
      "Sorted indices: [48, 33, 52, 51, 50, 49, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 0, 31, 54, 55, 56, 57, 58, 59, 60, 61, 62, 47, 30, 64, 28, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 29, 15, 17, 27, 26, 25, 24, 16, 22, 23, 19, 18, 53, 20, 35, 34, 42, 32, 63, 21] Sorted values: [3.  3.  3.  3.  3.  3.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      " 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      " 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      " 4.  4.  4.  4.2 5.  5.  5.  6.  6.  7.  7.8]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gnn_transformer'\n",
    "params = 'v2_repeat_1l1_rate_0.01_l2_rate_0.01_d_model_16_batch_size_64_n_layers_6'\n",
    "\n",
    "\n",
    "x = get_sorted_loo_array(model_name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48, 33, 52, 51, 50, 49, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 0, 31, 54, 55, 56, 57, 58, 59, 60, 61, 62, 47, 30, 64, 28, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 29, 15, 17, 27, 26, 25, 24, 16, 22, 23, 19, 18, 53, 20, 35, 34, 42, 32, 63, 21]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "x[0] = 48\n",
    "update_config_file('LOO_ARRAY', x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
